#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2025, Manchester (http://www.manchester.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-indent
#
# AIMetrics: []
#

    Target:

        Slack discussion with Indigo about the data model.

    Result:

        Work in progress ...

# -----------------------------------------------------

Abhishek Ghosh
Hi @Dave Morris
We have updated the software metadata structure to handle multiple locations.

    executable:
      name: canucs
      type: "docker-container"
      location: [ "location-1", "location-2" ]
      digest: "OCI image digest"

    metadata:
      description: "CANUCS is a tool for the analysis of CANFAR data."
      version: "1.3.0"
      tag: "1.3.0"
      authorName: "admin"
      specifications: [ "notebook" ]

    resources:
      cores:
        min: 5
        max: 15
      memory:
        min: 3
        max: 9

We are planning to add rest of the metadata from the latest offerset request structure like networks configuration and environment variables.
We are planning to introduce some new keys that will be relevant for a scientific platform to initiate a workload.
CC : @Anuja Chaitanya @Sayan Roy @Rajesh Tamhane

Dave Morris
Hiya, this is almost but not quite the same shape as the schema for the ExecutionBroker messages.

Dave Morris
Are there specific reasons why the structure ever so slightly is different ?

Anuja Chaitanya
HI@Dave Morris
If you are referring to resources section change, we have made resources section simpler, including only required cores and memory.  Is that the change you were referring to?
Also it would be great if we connect early in the next week to discuss the schema and further plans with service.
Also sent to the channel

Dave Morris
Hi@Anuja Chaitanya
yep, there are several small differences in the schema. I was wondering why ?

Dave Morris
If you have found parts of the ExecutionBroker schema that you think won't work I'm happy to discuss them and make changes to the schema where needed.
It is quite possible that I have got it wrong.

Dave Morris
The metadata section looks like your data about the software (more on that later) but the rest is almost but not quite like the ExecutionBroker schema.
Why the differences ?
The schema for the ExecutionBroker messages is here:
https://github.com/Zarquan/Calycopis-broker/tree/main/openapi/ivoa

Dave Morris
Sorry - that's my fork of the project, the main repo is here:
https://github.com/ivoa/Calycopis-broker/tree/main/openapi/ivoa

Abhishek Ghosh
Hi @Dave Morris
we had discussions around software metadata schema earlier and we made changes accordingly.
Would it be possible to have a discussion on this sometime early next week?

Dave Morris
@Abhishek Ghosh yep, I'm on UK time this week, I can be more flexible on time next week.
I'm always here on Slack if you want to talk about stuff.

Abhishek Ghosh
Thanks@Dave Morris
Would you be available on 9 UTC Monday ? We will schedule a call accordingly.

Dave Morris
11UTC ?

Abhishek Ghosh
Yes, that would be fine.

Dave Morris
First question will be ... Why did you choose to have almost the same but slightly different schema ?

OK, I take your point about the requested/offered part.
It would be better to discuss this here before you made any changes.
FYI, the plan is for WorkflowExecution to have the same API as ExecutionBroker, so the restructuring would have to happen before WorkflowExecution.
Why did you need to restructure the other parts of the message - moving the cores and memory out of the compute resource and making them part of the executable ?

Abhishek Ghosh
The cores and memory are still in the Resources, they are not part of the executables.
Software metadata in json.

    {
      "executable": {...},
      "metadata": {...},
      "resources": {
        "cores": {
          "min": 5,
          "max": 15
        },
        "memory": {
          "min": 3,
          "max": 9
        }
      }
    }

Dave Morris
https://github.com/Zarquan/Calycopis-broker/blob/ed70679505bce0c75f0f2bfa5db834924abbc047/examples/006/offerset-request.yaml#L27-L30

offerset-request.yaml
resources:
  compute:
  - name: compute-006
    type: https://www.purl.org/ivoa.net/EB/schema/types/resources/compute/simple-compute-resource-1.0

The ExecutionBroker structure provides space for other types of resources, including storage and data resources.
It also allows for other types of compute resources.

BTW I've opened an issue to re-visit the requested/offered properties in the data model.
https://github.com/ivoa/Calycopis-broker/issues/194

#194 Revisit requested/offered properties
Several properties in the data model have a requested and offered pair in the data model, which adds a complication to the metadata in the SoftwareDiscovery service.
Need to revisit this and see where it is explicitly needed in ExecutionBroker, and where we can simplify it to a single property.
If we no longer need the requested/offered pairs then we can remove them.

The goal of this project is to work together to evolve the data model so that all the components use the same structure.
Happy to make changes, but you need to tell me about them.
Can I make a suggestion - separate the two parts

    execution:
      # ExecutonBroker data model.
      executable:
        ....
      resources:
        compute:
          ....
        storage:
          ....
        data:
          ....

    discovery:
      # SoftwareDiscovery data model
      ....

ExecutionBroker secton is going to get more complex in the future.
I'm working on storage resources and data resources at the moment
This will include things like what types of data resources the executable requires e.g. spectra, cube, visibility etc ...
and how much and what kind of storage it needs

Abhishek Ghosh
I think the requested/offered would be useful in the execution broker context, but we can have a broader discussion around it on Monday.
And regarding the resources.compute.name and resources.compute.type we thought it can be added in the Workflow Execution API after consuming the software discovery API response.
But if the Workflow Execution API has the same API then you're right, we need to add that.

Dave Morris
The top right hand corner of the sequence diagram needs discussion with Jesus
AT the moment I'm not convinced it is quite right.

resources.compute is an array because some workloads require a cluster
you have dropped resources.compute and just put the cores and memory in resources

Abhishek Ghosh
Hey@Dave Morris
can we discuss this on Monday and finalize the software metadata model ?

Dave Morris
resources.compute[].type is needed to support different types of compute resources
The data model will be a moving target because we are both developing our components.
The goal of this project is to work together to evolve the data model so that all the components use the same structure.
Happy to discuss changes as and when they are needed.

Abhishek Ghosh
Actually, we were considering this only in the context of software requirementsâ€”meaning a software application only needs CPU, memory, and GPU to run anywhere, which is why we kept the structure a bit simpler.
That said, if you need this model to follow the same structure as the offerset request, we can do that as well.

Dave Morris
You are considering it in the context of a single simple unit of software.
What if the software is a Helm chart that needs a Kubernetes cluster with multiple compute nodes ?
There are reasons why we added all this to the ExecutionBroker data model.
A software application can be anything from a single Python program to a complex data reduction pipeline.
Which is why we added the type field
Set to simple-compute-resource-1.0 for now, but it leaves us space to have more complex things later.

Abhishek Ghosh
Okay, sure.
@Dave Morris We'll update the code and schema and let you know.

Dave Morris
If there are things you think need changing let me know in this channel or post an issue in GitHub.
I'll re-visit the requested/offered issue and get back to you.


